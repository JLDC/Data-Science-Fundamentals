{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "967bf562-9240-458a-841d-7649ddb7f3a0",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/JLDC/Data-Science-Fundamentals/blob/master/notebooks/06_linear-regression-varia.ipynb\">\n",
    "    <img src=\"https://i.ibb.co/2P3SLwK/colab.png\"  style=\"padding-bottom:5px;\" />Open this notebook in Google Colab\n",
    "</a>\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd6c1b0-bf69-4f5c-8b16-25cefc36ed21",
   "metadata": {},
   "source": [
    "# Linear Regression Model: Basics\n",
    "___\n",
    "We are going to cover the linear regression more in depth later in the first week of the break. However, you will need to understand some of the basics for the big assignment. This notebook will introduce you to those basics and we will refine them later in the course.\n",
    "\n",
    "Linear regression is the *Hello world!* of statistical modeling and machine learning. It is often considered the simplest statistical model out there and you will encounter it **a lot**. We recommend you pay close attention and try to understand as much as you can. It is not only a useful tool for your work and research but it is also a technique which permeates many modern studies. If you ever read a newspaper article about how *XYZ is bad or good for your health* and *ABC causes this or that*, chances are, there is a linear regression going on somewhere. In a sense, understanding linear regression (and other statistical models) gives you a new understanding of the world!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14d7ddf-ac54-4e5d-a18f-76c1fc0883c0",
   "metadata": {},
   "source": [
    "___\n",
    "## Data pre-processing\n",
    "We are going to work with bike rental data, which you may remember from the trial lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aee9264-66a4-4a4a-99f5-82535953b6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import matplotlib.pyplot as plt # Plotting\n",
    "import numpy as np # Numerical computing\n",
    "import pandas as pd # Dataframes\n",
    "\n",
    "# Import sklearn utilities\n",
    "from sklearn.linear_model import LinearRegression # Linear regression estimator\n",
    "from sklearn.model_selection import train_test_split # Train/test splitting\n",
    "\n",
    "# Define the path where the data is stored\n",
    "DATA_PATH = \"https://raw.githubusercontent.com/JLDC/Data-Science-Fundamentals/master/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22572b17-c2de-43c1-bb18-fb767283ab48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by importing the data\n",
    "rentals = pd.read_csv(f\"{DATA_PATH}/bike_rental.csv\")\n",
    "rentals.head(5) # Display the first 5 observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a350060b-d28c-4a37-8b9c-ce098bebf592",
   "metadata": {},
   "source": [
    "We will start by splitting the data into two datasets. One with roughly 75% and one with roughly 25% of the observations. In data science, we often talk about *training* and *testing* datasets. I don't won't to get ahead of myself too much, because we will cover this in detail later on, but the general idea is to have a dataset (*train*) which we use to **train** (or estimate or fit) our model, and another dataset (*test*) which we use to **test** (or validate) our model.\n",
    "\n",
    "While it is fairly simple to write our own code to split the data in two samples. The *conventional way* of doing it in data science is by using the `train_test_split` function from the `sklearn` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d456cb-b415-4906-8cff-f7208c9c60e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the indices of the dataset into two subsamples 75%/25%\n",
    "rentals1, rentals2 = train_test_split(rentals, test_size=0.25, random_state=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5a1273-8f00-41a6-95c4-1b9db1639d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that the size of the dataframes is what we expect\n",
    "print(f\"bike_rental_1 has {rentals1.shape[0]:>5} rows\")\n",
    "print(f\"bike_rental_2 has {rentals2.shape[0]:>5} rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6b5224-5c80-4c9d-8193-3fa173d30cfb",
   "metadata": {},
   "source": [
    "Now that we have our two datasets, let's keep working with the first one for the time being. What is the relationship between the outside temperature (`temp`) and the count of bike rentals (`cnt`)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c0d688-f1ed-49b3-bb5d-9a3067d69a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the canvas\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "# Make a scatterplot with temperature on the x-axis and number of rentals on the y axis\n",
    "ax.scatter(rentals1[\"temp\"], rentals1[\"cnt\"], alpha=0.4)\n",
    "# Add labels on the axes and a grid\n",
    "ax.grid(True)\n",
    "ax.set_xlabel(\"Normalized temperature in Celsius\")\n",
    "ax.set_ylabel(\"Number of rentals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac12e5f7-c721-4afd-adcb-d6702841cb0d",
   "metadata": {},
   "source": [
    "Do you see the lines? Why doesn't the temperature look continuous? You can find more information with regards to how the temperature is encoded on the dataset's website: https://archive.ics.uci.edu/ml/datasets/bike+sharing+dataset\n",
    "\n",
    "\n",
    "When we are making a scatter plot with data that has categorical or rounded x-values, e.g., as is the case for this normalized temperature. We get the lines we see above. This is slightly annoying, because it makes it *hard to read*. It's a bit unclear as to where the *mass* of the points is situated because they are all overlapping.\n",
    "\n",
    "What we can do is introduce **jitter**, i.e., we add some random noise to the x-value, so that the variables are not *exactly* on the line, but spread closely around them. Be careful to not make the noise too large, you don't want your data points to change completely!\n",
    "\n",
    "#### ‚û°Ô∏è ‚úèÔ∏è Task 1\n",
    "\n",
    "Replace the line\n",
    "```python \n",
    "ax.scatter(rentals1[\"temp\"], rentals1[\"cnt\"], alpha=0.4)\n",
    "``` \n",
    "\n",
    "with\n",
    "\n",
    "```python\n",
    "ax.scatter(rentals1[\"temp\"] + np.random.randn(rentals1.shape[0]) * .005, \n",
    "            rentals1[\"cnt\"], alpha=0.4)\n",
    "```\n",
    "\n",
    "Comment on the difference between both plots. Do you think one of them is easier/harder to interpret? Do you understand what \n",
    "```python\n",
    "... + np.random.randn(rentals1.shape[0]) * .005\n",
    "```\n",
    "is doing, and why we chose `0.005` ? (üôÄ ü§Ø This one is difficult, in particular if you haven't had a lot of statistics yet!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db89ca1a-c45a-44c2-9d8c-172b1c61c412",
   "metadata": {},
   "source": [
    "___\n",
    "## Our first linear regression\n",
    "Suppose that you now want to have a simple model, or *equation*, which indicates how the general tendency, or *trend*/*pattern* in this cloud of dots behave. \n",
    "\n",
    "The **linear regression** is one of the simplest ways to create such a model. The main idea is to estimate a line, i.e., a linear fit, for which the average squared distance to the line is minimal. The regression line is the one which is **closest** to the points.\n",
    "\n",
    "Fitting a linear regression with `sklearn` is very easy. Observe the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74484986-0172-42b7-98dc-ef0be4672e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the linear regression model\n",
    "linreg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057ceb05-0c59-49d1-b3b2-5653cec0a9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to our data\n",
    "# ‚ö†Ô∏è Careful with the double bracket around \"temp\". Don't think about it too much\n",
    "# for now, but the main idea is that our first input needs to be a matrix and not\n",
    "# a vector. We will look at this in more detail in later classes\n",
    "linreg.fit(rentals1[[\"temp\"]], rentals1[\"cnt\"])\n",
    "# cnt stands for count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e63399-cb42-42b4-9035-025325f55d61",
   "metadata": {},
   "source": [
    "That's it? Well yes, now we have fitted a linear regression model to the data. We can look at the coefficients estimate by this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e960b617-9887-4a73-a3d1-4b33471ba555",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The intercept is {linreg.intercept_:.2f}\")\n",
    "print(f\"The temperature coefficient is {linreg.coef_[0]:.2f}\")\n",
    "linreg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4569e9c-73f4-4fcb-bd38-fd7532aec5c7",
   "metadata": {},
   "source": [
    "So what the **intercept** and the **coefficient**? Well, above we mentioned something about estimating a *line* which best fits the data. You might remember that a line can be represented by\n",
    "\n",
    "$$y = a + mx$$\n",
    "\n",
    "In this case, $a$ is your intercept, and $m$ is your coefficient on $x$. So what this tells us is that we can model\n",
    "\n",
    "$$\\text{number of rentals} = 1.75 + 377.28 \\cdot \\text{normalized temperature}.$$\n",
    "\n",
    "But we are skipping a lot of details. You will learn about all of this as the course goes. In any case, now that we have a line, we can also plot it! Furthermore, we can use this equation to make predictions about the number of rentals for a given temperature level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b65e9e-d3fc-4f9f-b8c7-bcaf27bc0b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions from a fitted model with sklearn is very easy!\n",
    "rentals1[\"pred\"] = linreg.predict(rentals1[[\"temp\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981aca2e-0f34-4f1a-b009-37cf466b3134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The x-axis goes from 0 to 1, create a sequence from 0 to 1\n",
    "xs = np.linspace(0, 1, num=100)\n",
    "# Create the y = a + mx line described above\n",
    "ys = linreg.intercept_ + linreg.coef_ * xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559edbab-208d-4bd6-91c0-e1480a3f39fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the canvas\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "# Make a scatterplot with temperature on the x-axis and number of rentals on the y axis\n",
    "ax.scatter(rentals1[\"temp\"] + np.random.randn(rentals1.shape[0]) * .005, \n",
    "            rentals1[\"cnt\"], alpha=0.4, label=\"Data points\")\n",
    "# Add our straight line, make it orange and a bit wider such that it is visible\n",
    "ax.plot(xs, ys, label=\"Linear fit\", color=\"orange\", lw=3)\n",
    "# Add the predicted data points\n",
    "ax.scatter(rentals1[\"temp\"], rentals1[\"pred\"], label=\"Predicted points\", \n",
    "            color=\"orange\")\n",
    "# Add the predictions of our model using a scatter plot\n",
    "# Add labels on the axes, a legend, and a grid\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Normalized temperature in Celsius\")\n",
    "ax.set_ylabel(\"Number of rentals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957498fc-75c7-43f1-94ca-c7a9fff8f635",
   "metadata": {},
   "source": [
    "One of the strengths of linear regression (and other statistical models) is that they *abstract* a relationship between variables. Obviously, our model is not the best, but that's not the point here. Using a model, we have now an abstract way to formulate how the number of rentals changes as the temperature changes. Even better, we can use this abstraction on new data, we have never seen before, or, we could also make predictions on how many bikes we need to have in store depending on the weather forecast!\n",
    "\n",
    "Let's go ahead and predict the number of rentals for our second dataset, `rentals2`, which the model has never *seen* until now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5940562f-ba21-4efb-9882-6c9f831b3cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making prediction for new data is just as easy\n",
    "rentals2[\"pred\"] = linreg.predict(rentals2[[\"temp\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa21a12-84d0-4478-ba0c-b12dc2243d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat the same plot but for the second dataset\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "# Make a scatterplot with temperature on the x-axis and number of rentals on the y axis\n",
    "ax.scatter(rentals2[\"temp\"] + np.random.randn(rentals2.shape[0]) * .005, \n",
    "            rentals2[\"cnt\"], alpha=0.4, label=\"Data points\")\n",
    "# Add our straight line, make it orange and a bit wider such that it is visible\n",
    "ax.plot(xs, ys, label=\"Linear fit\", color=\"orange\", lw=3)\n",
    "# Add the predicted data points\n",
    "ax.scatter(rentals2[\"temp\"], rentals2[\"pred\"], label=\"Predicted points\", \n",
    "            color=\"orange\")\n",
    "# Add the predictions of our model using a scatter plot\n",
    "# Add labels on the axes, a legend, and a grid\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Normalized temperature in Celsius\")\n",
    "ax.set_ylabel(\"Number of rentals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3dd942-1920-4ffe-9fe3-977f147f8d63",
   "metadata": {},
   "source": [
    "___\n",
    "## Varia: Growth rates and cumulative growth\n",
    "\n",
    "Alright, that was a brief introduction to linear regression, you will get to play around with this much more during our workshop. Let's now add miscellaneous things that will help you when playing around with regressions and other statistical models, e.g. in your projects. They all relate to growth rates (rates of changes) and cumulative growth. This provides often a useful scaling of the data and delivers better predictive performance than level data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22def62f-8acb-45d6-a868-b39538209857",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(72) # Set the random seed\n",
    "# Create a random series \n",
    "myseries = .9 + np.random.rand(20) * .2\n",
    "myseries[0] = 1 # Set the first element to one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64add6c-740d-404f-9fce-790e13337670",
   "metadata": {},
   "outputs": [],
   "source": [
    "myseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accacf17-6cfe-4657-a9db-2e3fbd8f87c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the series\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.plot(myseries)\n",
    "# Add grid, axis ticks\n",
    "ax.grid(True)\n",
    "ax.set_xticks(range(myseries.shape[0]), range(1, myseries.shape[0] + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5457e74d-fc7f-4329-b0d6-0ab2e5de268a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a cumulative product to the series\n",
    "myseries2 = myseries.cumprod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0fe393-c8f0-480b-b7f7-d8460e1373a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the new series\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.plot(myseries2)\n",
    "# Add grid, axis ticks\n",
    "ax.grid(True)\n",
    "ax.set_xticks(range(myseries2.shape[0]), range(1, myseries2.shape[0] + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50c8fc8-2f16-47c9-bf88-31bc1c42e7bf",
   "metadata": {},
   "source": [
    "Can you see what `.cumprod()` did? What if we print out the series next to each other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d896723-6711-4d99-bfb5-5a236cccb17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the series next to each other\n",
    "series = pd.DataFrame({\"S1\": myseries, \"S2\": myseries2})\n",
    "series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee6a05c-c9ac-4db8-a13c-a9e8fbeb7b43",
   "metadata": {},
   "source": [
    "What if we instead want to compute the rate of change? Let's add a 3rd column to our dataframe. We now keep working with dataframes because they have a few nice functionalities for *time series operations* which are not implemented as nicely in `numpy` base."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74222ff-8100-4fbc-b902-555e20802270",
   "metadata": {},
   "source": [
    "### Shifting series by a specific lag\n",
    "\n",
    "`pandas` provides some amazing tools when it comes to data handling, one of them is the `.shift` method. It allows us to *shift* the data by a given number of lags (default is 1 lag). Consider the following example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6c4d44-025a-483e-9d35-d3860106b26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with one column (1, 2, 3, 4, 5)\n",
    "df = pd.DataFrame({\"A\": range(1, 6)})\n",
    "# Add a column which is the column A, but shifted by 1 lag\n",
    "df[\"B\"] = df[\"A\"].shift()\n",
    "# Add a column, which is the column A, but shifted by 3 lags\n",
    "df[\"C\"] = df[\"A\"].shift(3)\n",
    "df # Display the final dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c397f0-79a1-43eb-8df8-565d4d332bfa",
   "metadata": {},
   "source": [
    "Of course, we end up with some `NaN`. Do you see why?\n",
    "\n",
    "So what if we wanted to compute a growth rate? Consider that for a time series $\\mathbf{x} = \\{x_1, x_2, \\dots, x_T\\}$, the growth rate can be computed as \n",
    "\n",
    "$$\\text{growth rate at time } t = 100 \\cdot \\frac{x_t - x_{t-1}}{x_{t-1}}.$$\n",
    "\n",
    "Hence, we could use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341a06a8-8aab-4f86-95d3-98db575fec28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the growth rate\n",
    "series[\"GR1\"] = (series[\"S1\"] - series[\"S1\"].shift()) / series[\"S1\"].shift() * 100\n",
    "series # Show the result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34102744-0207-405e-9aa6-ebee2df51573",
   "metadata": {},
   "source": [
    "While this works, `pandas` is actually even simpler than this... observe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88237462-be88-49db-9201-a3f468b6d2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The better way to compute the growth rate\n",
    "series[\"GR2\"] = series[\"S1\"].pct_change() * 100\n",
    "series # Display the result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7696f5-b7d1-4ade-99ab-baf1d68bbac9",
   "metadata": {},
   "source": [
    "So `pandas` actually implements the method `.pct_change` which directly allows us to compute the growth rate, pretty nifty!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
