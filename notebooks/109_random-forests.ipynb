{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91236594-5e53-4c4e-a775-cd21ea51d5f2",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/JLDC/Data-Science-Fundamentals/blob/master/notebooks/109_random-forests.ipynb\">\n",
    "    <img src=\"https://i.ibb.co/2P3SLwK/colab.png\"  style=\"padding-bottom:5px;\" />Open this notebook in Google Colab\n",
    "</a>\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60541ca4-760b-4ce6-8aef-e7835f6623bb",
   "metadata": {},
   "source": [
    "# Random Forests\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1291864-21a7-47b4-bebe-1fd293ccf6ff",
   "metadata": {},
   "source": [
    "In this notebook, we will look into **random forests** and use them to predict real estate prices from individual residential properties. We will use data from real estate transactions in Ames, Iowa, collected between 2006 and 2010.\n",
    "\n",
    "This is a neat *real world* example. For instance, consider that you work as a data scientist consultant for a real estate agency. What you are going to learn below is typical of the work a data scientist might encounter in practice. With the exception that you would surely have spent a few days gathering and cleaning the data beforehand...\n",
    "\n",
    "[A relatively raw version of the data can be found on Kaggle](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data). Don't hesitate to have a look so you can get a feel of how much time it takes until you can run your first model. For now, we will simply provide a clean version of the data to spare time.\n",
    "\n",
    "If you want to read more on Random Forests, consult Chapter 8 of the book [Introduction to Statistical Learning](https://www.statlearning.com/) and [this blog](http://uc-r.github.io/2018/04/28/regression-trees/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edc6f9f-aa87-42e5-bd11-bf0c594d8481",
   "metadata": {},
   "source": [
    "___\n",
    "## Data pre-processing\n",
    "We already provide clean data, which we obtain from the R package [`AmesHousing`](https://cran.r-project.org/web/packages/AmesHousing/index.html). For more information on the variable content see: https://github.com/topepo/AmesHousing or https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65157b75-da58-43d1-8d43-b9dbf2cabdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # Plotting\n",
    "import numpy as np # Numerical computing\n",
    "import pandas as pd # Dataframes\n",
    "\n",
    "# Define the path where the data is stored\n",
    "DATA_PATH = \"https://raw.githubusercontent.com/JLDC/Data-Science-Fundamentals/master/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83eff57e-065a-4eee-8a2a-0a5695f26eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "ames = pd.read_csv(f\"{DATA_PATH}/ames_housing.csv\")\n",
    "ames # Display the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b78d1d5-426f-4b0d-b6ea-3c305e8635fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that there are no missing values\n",
    "ames.isnull().sum().max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9498627f-e024-4e35-88ff-f0a41a805f09",
   "metadata": {},
   "source": [
    "As mentioned above, we are interested in predicting the price of the residential properties, i.e., the `Sale_Price` column. Let's go ahead and create our features and targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13009c8-a1b7-40b9-a6ed-cbcb0b8b4d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features (notice the np.array(), this is to avoid a warning with random forests)\n",
    "X = np.array(pd.get_dummies(ames.drop(columns=[\"Sale_Price\"]), drop_first=True))\n",
    "# Targets\n",
    "y = ames[\"Sale_Price\"]\n",
    "X.shape # Display the shape of X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff48ec18-710e-4b01-9239-8f1e2e4d73ca",
   "metadata": {},
   "source": [
    "As the above cell shows, if we build dummies for every feature, we end up with a total of 306 feautres. Luckily for us, a high number of features is not necessarily a problem for random forests. It makes the computation a bit longer, but it should not impact the performance of our estimator much if we are careful to not overfit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba067b2-b8e7-4be0-9463-46bd08e0ab64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ebc694-1168-445a-aef3-618c00f0beef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our training and validation data\n",
    "Xtrain, Xval, ytrain, yval = train_test_split(X, y, test_size=0.33, random_state=72)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00561582-b08a-4b07-b02c-fb8772184041",
   "metadata": {
    "tags": []
   },
   "source": [
    "___\n",
    "## Fitting a random forest\n",
    "As with many of the `scikit-learn` models, the [`RandomForestRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor) comes with a lot of hyperparameters. We won't cover them in depth but when you are working with any model for your work or research, it is important that you understand what those hyperparameters do and which one you want to tune.\n",
    "\n",
    "The random forest estimator is a kind of modified bootstrap aggregating (**bagging**) of decision trees. The important difference between random forests and bagging is that random forests use *de-correlated* trees to improve on bagging. Using de-correlated trees will typically lower the prediction variance.\n",
    "\n",
    "So, how many trees are there in a forest? Well, this is one of the hyperparameters. The default value in `scikit-learn` is 100 but there's no reason that we shouldn't use something else. So we will start by comparing the performance of different forest sizes.\n",
    "\n",
    "How to compare the performance? Cross-validation seems like an intuitive choice. However, due to the time it takes to cross-validate many forests on such a large dataset, we will use the **out-of-bag error**.\n",
    "\n",
    "### Out-of-bag vs. validation error\n",
    "The typical method of growing a random forest consists in using **bootstrap samples** to build the trees. This implies that, for each tree, some of the training data has not been used for the fit. In consequence, we can use this data as an approximation of how well our tree would perform out-of-sample. The error we compute using this leftover data is named the **out-of-bag error**.\n",
    "\n",
    "So why would we use the out-of-bag error instead of the validation error? Well, we have the out-of-bag data *already* due to the way we are building each tree. Of course, we could use a validation set, or even cross-validation which would probably be better in terms of accuracy. However, this is much more costly to compute, whereas the out-of-bag error is much faster. In a sense, this is a trade-off between speed and accuracy. If your dataset is not too large and your computing power is enough, you might prefer running cross-validation. Let us start with the out-of-bag error to select our number of trees.\n",
    "\n",
    "The scikit-learn package only implements the R¬≤ (recall the notebook `106_ols-train-test-cv.ipynb`) as the out-of-bag score. However, it also provides a vector of out-of-bag predictions, such that we can use this vector to compute our own metric. This makes things slightly more complicated and we will have to add our own computations of MSE on out-of-bag predictions, but it's nothing we can't deal with!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6ba30b-718c-4748-9e27-cd30d57e7549",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor # Random Forest estimator\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error # Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53969c42-b962-4014-b7cb-dccd8445673c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrees = [25, 50, 75, 100, 150, 200, 250, 300, 350] # Number of trees\n",
    "# Instantiate lists to keep track of out-of-bag results\n",
    "oob_mse = []\n",
    "oob_mae = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299793ee-2999-4bb0-bef1-cccbe278e310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceed with forest growing (this might take a while)\n",
    "for trees in ntrees:\n",
    "    # Instantiate the estimator (notice the cost-complexity pruning)\n",
    "    # warm_start lets us continue growing the forest from the last instance; see https://www.kaggle.com/questions-and-answers/83501 for a more complete explanation.\n",
    "    forest = RandomForestRegressor(n_estimators=trees, ccp_alpha=0.01, \n",
    "                                   oob_score=True, warm_start=True, \n",
    "                                   random_state=144)\n",
    "    # Fit the model\n",
    "    forest.fit(Xtrain, ytrain)\n",
    "    # Store the out-of-bag MSE and MAE. Notice how it is on the TRAIN set\n",
    "    oob_mse.append(mean_squared_error(ytrain, forest.oob_prediction_))\n",
    "    oob_mae.append(mean_absolute_error(ytrain, forest.oob_prediction_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdc7f0e-e5b3-41a1-bba8-9f3969ac3536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time to visualize the results (plot the MSE)\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "# Compute best MSE\n",
    "best = np.argmin(oob_mse)\n",
    "# Plot out-of-bag error\n",
    "ax.step(ntrees, oob_mse, where=\"post\")\n",
    "# Plot best\n",
    "ax.scatter(ntrees[best], oob_mse[best], s=100, color=\"red\", label=\"Best\")\n",
    "# Add axis labels, grid, legend\n",
    "ax.set_xlabel(\"Number of trees\")\n",
    "ax.set_ylabel(\"Out-of-bag MSE\")\n",
    "ax.grid(True)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da83f9ba-8596-4e46-b8e3-4b71cdacc6a4",
   "metadata": {},
   "source": [
    "As the above plot shows, the largest forest, i.e., the one with 350 trees has the best out-of-bag MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbae004c-260d-4f4b-a559-9b1e61cab425",
   "metadata": {},
   "source": [
    "___\n",
    "#### ü§î Pause and ponder\n",
    "In this example, the best random forest (according to the oob score) is the one with the largest number of trees. If you were faced with this situation in your own work or research, what would you do? Would you pick this number of trees or would you try again with larger forests? Why?\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebea6d8-dbc2-449a-b550-db8d12789154",
   "metadata": {},
   "source": [
    "As we have already discussed previously in this course. The MSE can be difficult to interpret, thus we also want to have a look at the mean absolute error of our random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8172625-d400-4d3a-8f04-c0ebe38fc4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best MAE and compare it to the mean price of our training set\n",
    "print(f\"The best out-of-bag MAE is {oob_mae[best]:>9.2f}\")\n",
    "print(f\"The mean sales price is    {ytrain.mean():>9.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1acf018-b260-41bc-9600-87d018c5847b",
   "metadata": {},
   "source": [
    "We have discussed the difference between out-of-bag and validation errors above. Let us now look at it in practice. We will do as we did above and try random forests of different sizes, but this time, we will use different numbers of trees and we will compare the out-of-bag error with the error on a validation set.\n",
    "\n",
    "___\n",
    "#### ü§î Pause and ponder\n",
    "Before we go ahead and run the code below, do you have an intuition as to how the results might look like? Try to think a bit about it and try to justify your intuition.\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbd7537-6a78-4cd8-84b0-d173bff2f0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrees = range(50, 501, 50) # Number of trees\n",
    "# Instantiate lists to keep track of out-of-bag results\n",
    "oob_mse = []\n",
    "oob_mae = []\n",
    "# Instantiate lists to keep track of out-of-sample results\n",
    "oos_mse = []\n",
    "oos_mae = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dc1ce8-e5c4-41fd-b144-e071daf16221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceed with forest growing (this might take a while)\n",
    "for trees in ntrees:\n",
    "    # Instantiate the estimator (notice the cost-complexity pruning)\n",
    "    # warm_start lets us continue growing the forest from the last instance\n",
    "    forest = RandomForestRegressor(n_estimators=trees, ccp_alpha=0.01, \n",
    "                                   oob_score=True, warm_start=True, \n",
    "                                   random_state=144)\n",
    "    # Fit the model\n",
    "    forest.fit(Xtrain, ytrain)\n",
    "    # Store the out-of-bag MSE and MAE. Notice how it is on the TRAIN set\n",
    "    oob_mse.append(mean_squared_error(ytrain, forest.oob_prediction_))\n",
    "    oob_mae.append(mean_absolute_error(ytrain, forest.oob_prediction_))\n",
    "    # Compute the out-of-sample MSE and MAE. Notice how it is on the VALIDATION set\n",
    "    pred = forest.predict(Xval) # Predict on validation set\n",
    "    oos_mse.append(mean_squared_error(yval, pred))\n",
    "    oos_mae.append(mean_absolute_error(yval, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a79e6cf-099e-457a-acc7-c163678dd655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time to visualize the results (this time, we plot the MAE)\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "# Compute best MAE (out-of-bag)\n",
    "oob_best = np.argmin(oob_mae)\n",
    "# Compute best MAE (out-of-sample)\n",
    "oos_best = np.argmin(oos_mae)\n",
    "# Plot out-of-bag error\n",
    "ax.step(ntrees, oob_mae, where=\"post\", label=\"Out-of-bag\")\n",
    "# Plot out-of-sample error\n",
    "ax.step(ntrees, oos_mae, where=\"post\", label=\"Out-of-sample\")\n",
    "# Plot best out-of-bag\n",
    "ax.scatter(ntrees[oob_best], oob_mae[oob_best], s=100, color=\"red\", label=\"Best (OOB)\")\n",
    "# Plot best out-of-sample\n",
    "ax.scatter(ntrees[oos_best], oos_mae[oos_best], s=100, color=\"purple\", label=\"Best (OOS)\")\n",
    "# Add axis labels, grid, legend\n",
    "ax.set_xlabel(\"Number of trees\")\n",
    "ax.set_ylabel(\"Out-of-bag MSE\")\n",
    "ax.grid(True)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4494ae-0777-452b-bbd2-4004bafde337",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The best model (according to OOB selection) has :\")\n",
    "print(f\" - A total number of {ntrees[oob_best]} trees\")\n",
    "print(f\" - An out-of-bag mean absolute error of    {oob_mae[oob_best]:>10.2f}\")\n",
    "print(f\" - An out-of-sample mean absolute error of {oos_mae[oob_best]:>10.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483d60b1-5e53-471c-9def-60be01f7b845",
   "metadata": {},
   "source": [
    "#### ‚û°Ô∏è ‚úèÔ∏è Task 1\n",
    "What conclusions do you draw from the above plot? Was your intuition correct? Discuss with your classmates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcccbd10-322a-4d06-b6e0-52c9d07d74f2",
   "metadata": {},
   "source": [
    "## Comparison with linear regression\n",
    "___\n",
    "Let us now observe how the random forest model performs compared to a linear regression. We have seen above that, if we had used the out-of-bag error to select our model, the test error would not have been the lowest (it was lowest for 300 trees in the forest). For 450 trees (best model according to the out-of-bag selection), the mean absolute error on the **test set** is **15'607.28**, while the **out-of-bag** MAE is at **16'699.76**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250c6896-e694-4450-a7e9-1e9c510e2b39",
   "metadata": {},
   "source": [
    "\n",
    "#### ‚û°Ô∏è ‚úèÔ∏è Task 2\n",
    "Can you try to guess how the linear regression will perform compared to the random forest? Think about its performance:  \n",
    "+ on the training data, and\n",
    "+ on the validation data.\n",
    "\n",
    "Will it differ? Why? Discuss with your classmates before you run the code below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9125934-7b8b-4c7f-834b-e14f8de36ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b79aca-85a2-42ca-a650-a58e20c55e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the linear regression object\n",
    "linreg = LinearRegression()\n",
    "# Fit it to the training data\n",
    "linreg.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38567494-1358-494a-b23c-f53c8e56d9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the errors\n",
    "lr_mae_train = mean_absolute_error(ytrain, linreg.predict(Xtrain))\n",
    "lr_mae_val = mean_absolute_error(yval, linreg.predict(Xval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c020c547-1949-49d1-857b-6c6c26696450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results\n",
    "print(\"----- Training data MAE -----\")\n",
    "print(f\"Linear regression MAE : {lr_mae_train:>10.2f}\")\n",
    "print(f\"Random forest MAE     : {oob_mae[oob_best]:>10.2f}\")\n",
    "print() # Empty line\n",
    "print(\"----- Validation data MAE -----\")\n",
    "print(f\"Linear regression MAE : {lr_mae_val:>10.2f}\")\n",
    "print(f\"Random forest MAE     : {oos_mae[oob_best]:>10.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276c2801-1731-460a-8ea9-b02645875a67",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "___\n",
    "A **hyperparameter** is a parameter whose value is not learned during training. Instead it is used to control the learning process. We didn't discuss it in detail, but we have already seen a hyperparameter when looking at decision trees; this was the *cost-complexity pruning parameter* $\\alpha$ (`ccp_alpha`). There are a few hyperparameters that can be tuned when using a random forest, typically, you want to look at [the official documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) to better understand which hyperparameters are available and how they are implemented in the package you use. Some of the hyperparameters of the random forest implemented in scikit-learn are the following:\n",
    "\n",
    "+ `n_estimators`: The numbers of trees used to grow our forest, we have already played a bit with this hyperparameter above.\n",
    "+ `max_features`: The number of features considered at each split. Be sure to look at the documentation, we can use many different inputs for this value, e.g., the number of features as an integer or the fraction of features as a float.\n",
    "+ `min_samples_leaf`: The minimum number of samples required to be at a leaf node. A split will only be considered if there are at least `min_samples_leaf` in each of the resulting branches.\n",
    "+ `ccp_alpha`: The [cost-complexity pruning parameter](https://scikit-learn.org/stable/modules/tree.html#minimal-cost-complexity-pruning).\n",
    "\n",
    "Because hyperparameters are not derived during training, we have to think about how to select the best value of our hyperparameters. While there are [different strategies](https://scikit-learn.org/stable/modules/grid_search.html) to do so, **grid search** is the simplest method. If you consider what we did above with the size of the forest, we have already done hyperparameter tuning through grid search, i.e., we have selected the number of trees in the forest by trying out different values and choosing the best on the out-of-bag sample.\n",
    "\n",
    "The problem of grid search is that it can take a long time to run, because we are trying many different models. For instance, when considering $10$ different values for `n_estimators`, we have to grow $10$ forests. However, if we now also want to try $5$ values of `max_features`, we need to try $10 \\cdot 5=50$ models. Hence, as we want to tune more hyperparameters, and, as the grid search gets more granular, the number of models we need to estimate increases drastically.\n",
    "\n",
    "‚ö†Ô∏è Below, we provide an example of grid search for hyperparameter tuning. Because this can take a lot of time, **do not run it in class!** ‚ö†Ô∏è\n",
    "\n",
    "Note that, even at home, this will take very long to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b67e228-a8cb-4fa9-b27c-85de3f087a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV # Grid search function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994e55e7-2818-403b-bed0-c3475052616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if True: # Remove the 2 first lines to run the code, this is just a safeguard\n",
    "    raise Exception(\"Remove these two lines first\")\n",
    "    \n",
    "# Grid search on some hyperparameters\n",
    "hyperparams = {\n",
    "    \"n_estimators\": [100, 200, 300, 400],\n",
    "    \"max_features\": [0.25, 0.5, 1.0],\n",
    "    \"ccp_alpha\": [0, 0.001, 0.01],\n",
    "    \"min_samples_leaf\": [0.1, 0.25, 1]\n",
    "}\n",
    "# Run grid search cross validation\n",
    "forest = RandomForestRegressor()\n",
    "grid_search_forest = GridSearchCV(forest, hyperparams, verbose=1)\n",
    "grid_search_forest.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4691547-8992-4d4f-bb77-55100338ece1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
