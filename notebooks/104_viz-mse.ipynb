{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00bf3b74-20b7-48ef-9cea-a70687ea7856",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/JLDC/Data-Science-Fundamentals/blob/master/notebooks/104_viz-mse.ipynb\">\n",
    "    <img src=\"https://i.ibb.co/2P3SLwK/colab.png\"  style=\"padding-bottom:5px;\" />Open this notebook in Google Colab\n",
    "</a>\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd23428e-6ef2-4d1d-b4cc-2c99eeb9e466",
   "metadata": {},
   "source": [
    "# Coding and Visualizing the Mean Squared Error (MSE)\n",
    "___\n",
    "We have seen (with the WDBC data) that a purely heuristic ad-hoc specification of a learning procedure does not always work well. Hence, we need to think about *\"first principles\"* of a good learning procedure. These imply setting up a learning problem as a minimization problem, where the objective function relates to prediction errors. We also need to make sure that this function has nice properties, i.e., that it is continuous and differentiable.\n",
    "A very common choice for such an objective function is the mean squared error function (MSE). (Others are the likelihood function, Gini, and cross-entropy. More on them later.)\n",
    "\n",
    "The aim of this notebook is to give you an intuition about the MSE concept. What does it depend on, how does it look like? On paper, when you see it the first time, it may feel pretty abstract. Hopefully, this notebook helps you understand the concept of the MSE better and make it more colorful (literally).\n",
    "\n",
    "### üßë‚Äçüíª <font color=green>**Your Task**</font>\n",
    "\n",
    "Go through the explanations and code pieces of this notebook and solve the questions outlined below. <font color=red>**Feel free to work in groups!**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2226f45-40c1-434e-b598-bfe5ec2c7e50",
   "metadata": {},
   "source": [
    "___\n",
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7549f7e8-33b3-457d-b3e5-cfce3239df49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import numpy as np # Numerical computation package\n",
    "import pandas as pd # Dataframe package\n",
    "import matplotlib.pyplot as plt # Plotting package\n",
    "import matplotlib as mpl # To use colormaps later on\n",
    "np.random.seed(1) # Set the random seed for reproduceability\n",
    "\n",
    "# Define the path where the data is stored\n",
    "DATA_PATH = \"https://raw.githubusercontent.com/JLDC/Data-Science-Fundamentals/master/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4546db21-d15b-4da6-89c7-beea916b43a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the WDBC dataset\n",
    "wdbc = pd.read_csv(f\"{DATA_PATH}/wdbc.csv\")\n",
    "# Keep only necessary columns: the diagnosis, the perimeter, and the severity of concave portions\n",
    "# of the cell nucleus\n",
    "wdbc = wdbc[[\"perimeterM\", \"concaveM\", \"diagnosis\"]]\n",
    "# Shuffle the dataset\n",
    "wdbc = wdbc.sample(frac=1)\n",
    "wdbc.head(5) # Display the first rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e25232-5a5a-44ea-ad34-439b9f136edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for vector standardization\n",
    "standardize = lambda x: (x - np.mean(x)) / np.std(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d095b5-e9cc-4959-9fb3-2e7f9d8197d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features\n",
    "wdbc[[\"perimeterM\", \"concaveM\"]] = wdbc[[\"perimeterM\", \"concaveM\"]].apply(standardize)\n",
    "wdbc.head(5) # Display the first rows with standardized features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36dc889-6685-4338-9e34-beb50d0ef3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the matrix of features\n",
    "X = np.array(wdbc[[\"perimeterM\", \"concaveM\"]])\n",
    "# Create the vector of labels / targets\n",
    "y = np.where(wdbc[\"diagnosis\"] == \"M\", 1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0350a0c-7fb1-428e-8520-3d52576780ad",
   "metadata": {},
   "source": [
    "___\n",
    "## The loss function landscape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4783196-ca79-4758-ac93-c7cfaaaaa813",
   "metadata": {},
   "source": [
    "___\n",
    "#### ‚û°Ô∏è ‚úèÔ∏è<font color=green>**Question 1**</font>\n",
    "\n",
    "1. Make a drawing of how you envisage the MSE as a function of two weights $w_1$ and $w_2$ (as *\"independent/free variables\"*). \n",
    "2. Draw a coordinate system with the weight dimensions as \"$x$\" and \"$y$\" variables (*\"in the plane\"*), and with the MSE as the third (\"$z$\") dimension (the *\"spatial dimension\"*). To be clear, with \"$x$\" and \"$y$\" we do not mean features and targets but generic variables in the mathematical sense (think about high school math, even if this may feel unpleasant ;-).\n",
    "3. What does a high or low $z$ dimension mean? \n",
    "4. If you could dream up a learning machine with a really \"good engineering\", how would you try to construct an *\"ideal\"* MSE for this good engineering? What would be a sensible meaning of \"good engineeering\"?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84884af3-98c3-48a0-aeb5-6299ac9d477f",
   "metadata": {},
   "source": [
    "___\n",
    "### Visualizing the MSE\n",
    "\n",
    "Let us now plot the MSE drawing discussed in Question 1. Say that our learning problem only contains two elements, namely the two weights $w_1$ and $w_2$ (there is no bias $b$ or constant $w_0$ in this case; why?). For every $(w_1, w_2)$ point, we can compute the corresponding predictions $\\hat{\\mathbf{y}}$ for the target. And hence we can compute and plot the MSE $\\frac{1}{N}\\sum_{i=1}^N \\left(\\hat{y}^{(i)} - y^{(i)}\\right)^2$. This is a function of the weights! (Why?) Hence, we can write $MSE = MSE(w_1, w_2)$ &ndash; make sure this makes intuitive sense to you!\n",
    "\n",
    "A good way to represent a three-dimensional relationship is either a [contour plot](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.contour.html) or a [3D surface](https://matplotlib.org/stable/gallery/mplot3d/surface3d.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0958624c-7696-4575-ad9e-82a36d0185c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the bounds of the weights grid: each weight goes from -10 to +10\n",
    "wbounds = [-10, 10]\n",
    "# Define the number of points we use to plot the weights, i.e., the 'granularity'\n",
    "npoints = 41\n",
    "# Create the w1 (\"x\") coordinates and the w2 (\"y\") coordinates as linearly spaced points\n",
    "w1_vec = np.linspace(*wbounds, num=npoints)\n",
    "w2_vec = np.linspace(*wbounds, num=npoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bbb4bb-437e-4af0-9a4c-82be20c63109",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee32842-d9a3-488f-bff3-1d396d680d85",
   "metadata": {},
   "source": [
    "Now that we defined our weight vectors `w1_vec` and `w2_vec`, let's create an `MSE` matrix with the MSE value for each combination of `w1` and `w2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8f8308-4c64-496f-9725-e3e94cea64ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a npoints x npoints empty matrix\n",
    "mse = np.empty([npoints, npoints])\n",
    "# Iterate over every weight combination\n",
    "for i in range(npoints):\n",
    "    for j in range(npoints):\n",
    "        # Obtain the weights for this specific combination\n",
    "        w1, w2 = w1_vec[i], w2_vec[j]\n",
    "        \n",
    "        # The prediction on this point in the grid\n",
    "        pred = w1 * X[:, 0] + w2 * X[:, 1]\n",
    "\n",
    "        # Compute the MSE and store it to the corresponding index\n",
    "        # The MSE is the mean squared error over all the dataset, the division by 2\n",
    "        # is only a rescaling (see the slides).\n",
    "        mse[j, i] = np.mean((y - pred) ** 2) / 2\n",
    "        # üôÄ ü§Ø Notice that the indexing is [j, i] and not [i, j]. This is confusing.\n",
    "        # In fact, when we use a 3D plot in Matplotlib, the x-axis values are in the\n",
    "        # columns and the y-axis values in the rows of our matrix.\n",
    "        \n",
    "# Lastly, for 3D plots, we need to create a so-called meshgrid for the X- and Y-axes\n",
    "x_axis, y_axis = np.meshgrid(w1_vec, w2_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44902de-84bb-4220-8fed-8252af90d7b2",
   "metadata": {},
   "source": [
    "... and now let's visualize our results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc08ec2-d311-47c4-a946-5745b462c37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the canvas. Notice the subplot_kw, this is needed for a 3d plot\n",
    "# (No need to understand the details of this visualization; get back to it when you need something like this)\n",
    "fig, ax = plt.subplots(figsize=(12, 8), subplot_kw={\"projection\": \"3d\"})\n",
    "# Draw a surface plot\n",
    "ax.plot_surface(x_axis, y_axis, mse, cmap=mpl.colormaps[\"viridis\"], alpha=0.9)\n",
    "\n",
    "# Notice the TeX notation in the axis labels!\n",
    "ax.set_xlabel(\"$w_1$\")\n",
    "ax.set_ylabel(\"$w_2$\")\n",
    "ax.set_zlabel(\"MSE\")\n",
    "# Change perspective\n",
    "ax.view_init(azim=-35, elev=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf357cf6-d890-4176-b710-bc67eb14ef69",
   "metadata": {},
   "source": [
    "___\n",
    "#### ‚û°Ô∏è ‚úèÔ∏è<font color=green>**Question 2**</font>\n",
    "\n",
    "How does this MSE plot relate to the construction of a learning machine? Why are we interested in the MSE? What do we want to find? How would you relate it to a learning task for the iris or WDBC data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f36780-d38d-4497-ba01-5d89200ebb77",
   "metadata": {},
   "source": [
    "___\n",
    "#### üôÄ ü§Ø Finding the minimum in a multidimensional array (e.g., matrix) in `numpy`\n",
    "\n",
    "A plot is nice to understand the general relationship between weights and MSE, but it's difficult to find the optimal weights just by looking at the graph. Let's find the minimum in our MSE matrix numerically.\n",
    "\n",
    "While finding the minimum value of a matrix (or other multidimensional array) is relatively straighforward, extracting the index of this element is slightly more cryptic.\n",
    "\n",
    "For instance, with our `mse` matrix, the minimum value can be obtained using `mse.min()`. Easy enough! To find the corresponding index, we can just use `mse.argmin()`, however, if you try it out, you will notice that it does not yield a tuple with the index amongst each dimension. Instead, we get a single number. The problem is that it returns the index for the *flattened* matrix. The `numpy` syntax to obtain the index on each dimension from the *flattened* index is the following:\n",
    "\n",
    "```python\n",
    "multidimensional_index = np.unravel_index(flattened_index, shape_of_the_multidimensional_array)\n",
    "```\n",
    "\n",
    "There is no neeed to understand this in detail. You have seen it now and you know there is this issue... Get back to here if you need something similar!\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aac3c5-a50e-4e3b-bc38-14a993e5d4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the index of the best weights\n",
    "w_index = np.array(np.unravel_index(mse.argmin(), mse.shape))\n",
    "# Map index to corresponding weights and store in a vector\n",
    "w_best = np.array([w1_vec[w_index[0]], w2_vec[w_index[1]]])\n",
    "w_best # Display best weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d19cd77-0e2d-4638-9d7d-c847f8c400be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the smallest value of the mse\n",
    "mse.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd93b591-146d-46de-8496-28abb877fdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can ignore this code, the important thing is the resulting 3D plot!\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# 3D plotting helper\n",
    "def plot_mse_3D(w1_vec, w2_vec, mse):\n",
    "    # Obtain the index of the best weights\n",
    "    w_index = np.array(np.unravel_index(mse.argmin(), mse.shape))\n",
    "\n",
    "    fig = go.Figure(\n",
    "        data=[\n",
    "            go.Surface(z=mse, x=w1_vec, y=w2_vec, opacity=0.9),\n",
    "            go.Scatter3d(x=[w1_vec[w_index[0]]], y=[w2_vec[w_index[1]]], \n",
    "                         z=[mse.min()])\n",
    "        ]\n",
    "    )\n",
    "    fig.update_layout(title='Mean Squared Error Surface', height=600, width=800, \n",
    "                      autosize=False,\n",
    "                      scene=dict(xaxis_title=\"w1\", yaxis_title=\"w2\", \n",
    "                                 zaxis_title=\"MSE\")\n",
    "    )\n",
    "    fig.show()\n",
    "    \n",
    "# Use the function to plot our MSE landscape\n",
    "plot_mse_3D(w1_vec, w2_vec, mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f025e443-214d-4fc5-bbd1-c88441e2fed6",
   "metadata": {},
   "source": [
    "___\n",
    "#### ‚û°Ô∏è ‚úèÔ∏è<font color=green>**Question 3**</font>\n",
    "1. Does the lowest MSE value and the corresponding weight vector change if we choose a more granular grid (i.e., if we raise the value of `npoints`)?\n",
    "2. What is a good grid size? Is there a problem with making the grid as granular as possible (i.e., `npoints` as large as possible)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64656ee-782b-4636-8502-0177e825b223",
   "metadata": {},
   "source": [
    "___\n",
    "#### ‚û°Ô∏è ‚úèÔ∏è<font color=green>**Question 4**</font>\n",
    "1. Could we still calculate the MSE the way we did if we had 3 weights $w_1$, $w_2$, and $w_3$ ? What about any positive number of weights $p > 0$?\n",
    "2. Could you still visualize the MSE with 3 weights?\n",
    "3. Could you still visualize the MSE with any positive number of weights $p> 0$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2918e16-5854-4494-9ad0-ca75d0468e1a",
   "metadata": {},
   "source": [
    "___\n",
    "#### ‚û°Ô∏è ‚úèÔ∏è <font color=green>**Question 5**</font>\n",
    "1. Concerning the difficulty you may have encountered in *Question 3*, do you expect this difficulty to become less or more severe if we had more weights? \n",
    "2. If this problem becomes really severe, can you think of an alternative way to find the weights that lead to the minimum of the MSE?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b130c3-fdf2-4130-853f-048feef0e1ed",
   "metadata": {},
   "source": [
    "___\n",
    "#### ‚û°Ô∏è ‚úèÔ∏è<font color=green>**Question 6**</font>\n",
    "Suppose we used some other dataset. What kind of changes would you expect in the visualization of the MSE? Do you think the shape of the MSE will change or would you expect it to keep this kind of U-shape?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b136c34-6f82-477d-9e3d-134fa4b5c59e",
   "metadata": {
    "tags": []
   },
   "source": [
    "___\n",
    "#### ‚û°Ô∏è ‚úèÔ∏è <font color=green>**Question 7**</font>\n",
    "In light of your results to *Question 6*, is the MSE a function of the data or the weights?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
