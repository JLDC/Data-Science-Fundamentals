{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc4b1ef4-04e2-4f33-bd1a-d797135b596f",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/JLDC/Data-Science-Fundamentals/blob/master/notebooks/005_exchange-rate-data.ipynb\">\n",
    "    <img src=\"https://i.ibb.co/2P3SLwK/colab.png\"  style=\"padding-bottom:5px;\" />Open this notebook in Google Colab\n",
    "</a>\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb7f942-cebe-4591-af3c-04f92330ab63",
   "metadata": {},
   "source": [
    "# Preprocessing Exchange Rate Data\n",
    "___\n",
    "In this notebook, we will study how to read data from external sources into Python. You will see that we are confronted with a rather tricky case that is more demanding than when you work with already clean data. However, this will allow us to get to learn some functions to help us put the information in the necessary format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6b3616-72ab-4084-9dad-cb0ce60e3878",
   "metadata": {},
   "source": [
    "___\n",
    "## Getting and reading SNB data on exchange rates\n",
    "We are going to use pre-construted CSV file in order to save time at the start of the course. However, it is important that you learn how to find and download data yourself. Therefore, you will also find a description on how to download the data from the source: the data portal of the Swiss National Bank (SNB). We highly recommend you go over this description and test out the steps for yourself.\n",
    "\n",
    "### Instructions to obtain the data\n",
    "1. Go to the data portal of the Swiss National Bank: https://data.snb.ch/en.\n",
    "2. Make sure to switch to ENGLISH (in the upper right corner), if necessary.\n",
    "3. Choose table selection in the upper horizontal menu bar and then **Interest rates, yields and foreign exchange market**. \n",
    "4. Choose **Foreign exchange market > Foreign exchange rates > Month** in the left menu bar.\n",
    "5. Choose data (**Monthly average**) from January 2001 to most recent, in CSV format (choose **CSV (selection)**, <span style=\"color:red\">**not CSV (all)!**</span>).\n",
    "\n",
    "Accessing the data on Jun 30, 2022, we obtain a file named `snb-data-devkum-en-selection-20220630_1430.csv`. You find it in the data folder on Nuvolos.\n",
    "\n",
    "___\n",
    "⚠️ <span style=\"color:red\">**BE CAREFUL WHEN OPENING  CSV FILES in Excel!**</span> ⚠️\n",
    "\n",
    "Depending on country settings of your device, Excel may change formats automatically, which will make it difficult to import that data into Python. The easiest way to inspect the data is to go to the data folder in Jupyter Lab's file browser (left pane) and double-click on the CSV file. Alternatively, you can download the file and open it with a text editor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe2fe0b-003e-4035-abb5-b95c75cd0625",
   "metadata": {},
   "source": [
    "___\n",
    "## Path, directories, and data import\n",
    "\n",
    "Do you remember how we imported the **iris** dataset last class? We used\n",
    "\n",
    "```python\n",
    "iris = pd.read_csv(\"../data/iris.csv\")\n",
    "```\n",
    "While it truly is simple, we omitted some important points. We are opening a dataset, called `iris.csv`, which is located in the folder `data`, one directory layer above the current one (`notebooks`). Oftentimes, you might want to refer to a file that is somewhere on your computer, not necessarily always in the same folder (or a sub-folder in this case). Perhaps, if you are working on Windows, you have the two following folders (I hope you don't! This is a *bad* example):\n",
    "+ `C:/notebooks/mynotebook.ipynb`\n",
    "+ `C:/data/iris.csv`\n",
    "\n",
    "How do you import `iris.csv` from `mynotebook.ipynb`? You can't simply do `pd.read_csv(\"data/iris.csv\")` because **from the point of view of `notebook.ipynb`** (i.e., the current folder it is in `C:/notebooks`) there is no `data` folder. So, what can we do?\n",
    "\n",
    "#### Absolute paths\n",
    "The first method is to simply pass the absolute path, i.e., the path *starting from the base of the directories on your operating system*, e.g.\n",
    "\n",
    "```python\n",
    "pd.read_csv(\"C:/data/iris.csv\")\n",
    "```\n",
    "This works fine, but if your folder structure is complicated this might be cumbersome.\n",
    "\n",
    "#### Relative paths\n",
    "Another way to do it is using relative paths, i.e., relative to *where we are currently*. This is implicitly what we did when loading the iris dataset, we use a path, relative to the notebook we were working in. In a case as the one portrayed above, we need to know how to *go back one folder* using relative path notation, this is done by adding `..`, e.g.,\n",
    "\n",
    "```python\n",
    "pd.read_csv(\"../data/iris.csv\")\n",
    "```\n",
    "\n",
    "For a more complicated example, consider that your are working with a notebook and a dataset situated as follow:  \n",
    "+ `C:/HSG/HS2022/DSF/my-project/notebooks/stock_market_prediction.ipynb`\n",
    "+ `C:/HSG/HS2022/DSF/data/datasets/stock_market_data.csv`\n",
    "\n",
    "Can you figure out what you need to type to read the CSV using relative paths?\n",
    "\n",
    "The answer is\n",
    "```python\n",
    "pd.read_csv(\"../../data/datasets/stock_market_data.csv\")\n",
    "```\n",
    "Do you see why? The first `..` takes us one folder back, i.e. into `my-project`, but the `data` folder is not in here! So we need another `..` to go back one more folder.\n",
    "\n",
    "This might all see a bit abstract and complicated. In my opinion, it's best to have your files all together in your project folder. A bit like how the folder for this class is structured! For instance, in my research, I try to have a main folder, e.g., `my-project` and inside, I will have a `data` folder, a `code` folder, and something like a `latex` folder where I keep my writings on the subject.\n",
    "\n",
    "#### ⚠️ Backward and forward slashes\n",
    "\n",
    "Sometimes, you might see a path written as  \n",
    "+ `..\\\\data\\\\iris.csv`\n",
    "\n",
    "This is some Windows-specific notation. **This is bad practice**, for two main reasons:  \n",
    "+ It only works with windows. If somebody working on a unix system (Mac, Linux) tries to run your code it will fail.\n",
    "+ Backslash is a special character for strings called an *escape character*. This is a bit advanced, but for instance `\\n` is a newline, `\\t` is a tab, etc.\n",
    "+ (Optional) It's one more character than you need.\n",
    "\n",
    "So, to summarize, just use forward slashes. They work on all systems and use less characters. \n",
    "\n",
    "**⛔ There is never a good reason to use `\\\\` instead of `/` when indicating a path! ⛔**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1722530a-8ed2-4534-8052-57ca0ce9c34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Import the dataframes package\n",
    "\n",
    "# Define the path where the data is stored\n",
    "DATA_PATH = \"https://raw.githubusercontent.com/JLDC/Data-Science-Fundamentals/master/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4dc0c3-fa6a-4390-bc4e-de72329ad580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv() is the default function in pandas to load a csv as a dataframe\n",
    "pd.read_csv(f\"{DATA_PATH}/snb-data-devkum-en-selection-20220601_1430.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4722b50-b1dc-4535-803b-f86a9e4fcf85",
   "metadata": {},
   "source": [
    "As we can see from the output of the code above, reading the CSV into dataframe format with `pandas` produces a strange result. Have we done something wrong?\n",
    "\n",
    "Well, not exactly, but as mentioned above, the data you download does not always come in a clean format and sometimes you will need to inspect the data yourself to understand what needs to be done before you can import it properly.\n",
    "\n",
    "Looking either at the output above, or at the file directly by double-clicking on it in the explorer, we observe a few things:\n",
    "+ The 2 first rows are separated from the rest by a blank row. Also, these rows are *different*. In fact, they have only 2 elements separated by `;`, whereas the later rows always have 4.\n",
    "+ The values are separated by a semi-colon (`;`) instead of a comma(`,`). As it turns out, the elements in a CSV file are not always separated by a comma, the separator can be something else (often a semi-colon, but sometimes it can also be something else, this is something you will have to find out). In particular, the Swiss standard for CSV differs from the more widely spread American one. The semi-colon is the typical separator for CSV files with Swiss format!\n",
    "\n",
    "Taking those two observations into consideration, we can try to import our CSV from the row 4 onwards, using a semi-colon separator. Can you figure out how to do it yourself?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64279e2c-41aa-4085-8c0e-40ecfe31da15",
   "metadata": {},
   "source": [
    "#### ➡️ ✏️ Task 1\n",
    "\n",
    "In the cell below, read in the SNB data by passing options to deal with the issues noted above.\n",
    "\n",
    "*Hint:* Having a look at the [`pandas` documentation](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html) is always helpful to understand what options we can pass to a specific function. In particular, you want to look at the arguments `skiprows` and `sep`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f62e6a6-4ee2-47cc-8187-0a5b9f94d5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23f6136-7934-4594-b284-1f8ec82b359c",
   "metadata": {},
   "source": [
    "The clean dataframe consists of 4 columns: `Date`, `D0`, `D1`, and `Value`. The names `D0` and `D1` are not very expressive, it would be better to rename those columns. In any case, let's start with some data pre-processing, **as always**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5502146-a3e6-4d40-b040-a25f44e02c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the unique 'Date' values\n",
    "snb[\"Date\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c4f093-abfb-4c2b-904a-982736526d96",
   "metadata": {},
   "source": [
    "The dates are actually months, in the format `yyyy-mm`. However, they are currently stored as strings in our dataframe. This is not very practical, it would be nicer to have them as date. Fortunately, `pandas` provide some useful utilities for this purpose.\n",
    "\n",
    "In general, when using the function `pd.to_datetime()` (or other date functions in Python), we want to pass the format in which the date is currently being represented. Python works with [well-defined date format codes](https://docs.python.org/3/library/datetime.html#strftime-and-strptime-format-codes). These can seem a bit cryptic at first, but once you get the hang of it, it becomes intuitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7017d77-5e83-4950-aa23-6d7e44d3266e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the date column to date format\n",
    "snb[\"Date\"] = pd.to_datetime(snb[\"Date\"], format=\"%Y-%m\")\n",
    "snb[\"Date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d5a6c2-3a67-4cac-8018-023199c73d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the unique 'D0' values\n",
    "snb[\"D0\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8dfe54-f9c2-4dfd-86ab-5af512a018b6",
   "metadata": {},
   "source": [
    "The `D0` column in our dataframe only consists of the value `M0`. This is not very useful information, thus we might as well drop this column.\n",
    "\n",
    "#### ➡️ ✏️ Task 2\n",
    "In the cell below, remove the column `D0` from the `snb` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21b67bf-58a8-4e62-bbb9-418a3b76e4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed63394f-b89e-4207-be46-aa5b7eac4230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the unique values in D1\n",
    "snb[\"D1\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e6b70d-df7e-4bfe-bf12-95db802ca97f",
   "metadata": {},
   "source": [
    "As we can see, the column `D1` contains the different currencies (28 in total). Because the name `D1` is not very helpful, we rename the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f34a00a-8946-4c15-835f-91dfc67bf498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the column 'D1' to 'Currency'\n",
    "snb.rename(columns={\"D1\": \"Currency\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c19fb3c-25bc-4bca-9748-2296032704e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "snb # Display the cleaned data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1462af31-0462-4eed-b255-1373f2b92521",
   "metadata": {},
   "source": [
    "___\n",
    "## Selecting data subsets and plotting\n",
    "\n",
    "Now that we have pre-processed our data, we can turn to visualizations. Once again, we will need to load the plotting libary `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed8c5d2-46db-4e01-87fb-58f6002a2c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6812ffde-f992-42f6-8057-1fc416a8bc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict = {\"EUR1\": \"blue\", \"USD1\": \"green\"} # Create a color mapping\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8)) # Instantiate the figure and axis\n",
    "# Iterate over the keys of the color dictionary (EUR1, USD1)\n",
    "for currency in color_dict.keys():\n",
    "    subset = snb.loc[snb[\"Currency\"] == currency, :] # Subset the data\n",
    "    ax.plot(subset[\"Date\"], subset[\"Value\"], label = currency, color = color_dict[currency])\n",
    "ax.legend() # Add legend\n",
    "# Set x- and y-labels\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"Exchange rate (in CHF)\")\n",
    "ax.grid(True) # Add a grid in the basckground"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934506fb-f639-4c38-8573-45ac37c547ef",
   "metadata": {},
   "source": [
    "#### ➡️ ✏️ Task 3\n",
    "In the cell below, add the exchange rate of the pound (`GBP1`) in purple, and the exchange rate of the canadian dollar (`CAD1`) in orange.\n",
    "\n",
    "*Hint:* Look at the `color_dict` and try to understand what is happening the the loop over `color_dict.keys()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5247ffb2-e03c-442b-8d70-6fdcd2cdd847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa864ae-1d52-431d-bab6-b09a52fd1468",
   "metadata": {},
   "source": [
    "___\n",
    "## Saving our clean data\n",
    "\n",
    "While it is necessary to pre-process every dataset you receive, you don't want to re-run the code every single time you are working with this dataset. Instead, you want to save a clean version of the data that you will re-use. In general, I personally separate the data pre-processing and the data analysis steps, i.e., I will have a notebook or script for the data cleaning and another one for the analysis.\n",
    "\n",
    "`pandas` provides the method `.to_csv` which allows us to save our data back to CSV format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57367890-a7b3-4313-be07-e786df5190a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the clean data as a CSV and ignore the index\n",
    "snb.to_csv(\"snb_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56703157-4f86-490c-8084-9f75c618245f",
   "metadata": {},
   "source": [
    "Check the data folder, there is now a file called `snb_clean.csv` with the contents of our pre-processing step. Next time we can only use `pd.read_csv(\"data/snb_clean.csv\")` and skip the whole pre-processing!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
