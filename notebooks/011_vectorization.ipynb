{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34231c7f-1a94-4a7f-8154-739ab6032d09",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/JLDC/Data-Science-Fundamentals/blob/master/notebooks/011_vectorization.ipynb\">\n",
    "    <img src=\"https://i.ibb.co/2P3SLwK/colab.png\"  style=\"padding-bottom:5px;\" />Open this notebook in Google Colab\n",
    "</a>\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12af559a-8f52-4a40-9d03-9b4fc1f10fe7",
   "metadata": {},
   "source": [
    "# Vectorization\n",
    "___\n",
    "\n",
    "In this notebook, we wil have a look at **vectorization**. Vectorization is one of the most important concepts to understand when working with large amounts of data. Applying vectorization to loops will speed up your code in tremendous ways and it will gain you a lot of time. Using plain Python loops without vectorizing them is one of the most common mistake that beginner data scientists make when starting to work with pandas and NumPy.\n",
    "\n",
    "To make a long story short, vectorization refers to applying the same function multiple times to a `numpy` array, or a column in a `pandas` dataframe, **and it will substantially decrease the runtime your code needs!**\n",
    "\n",
    "Everytime you write a loop that loops over your full data (or large parts of it), you should think: **\"Is there a way to vectorize this loop?\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7899df5e-3f12-402a-b705-b9a9c1cf7d35",
   "metadata": {},
   "source": [
    "Let's have a look at vectorization in a data cleaning context. Say that your client has a large datasets of multiple thousands of observations of stock returns for multiple companies in long format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a730cf4-abd3-4b50-95b8-40cdf8fb033b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the path where the data is stored\n",
    "DATA_PATH = \"https://raw.githubusercontent.com/JLDC/Data-Science-Fundamentals/master/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65c95e2-410e-47f4-8303-9cf33e809a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the stock data\n",
    "stocks = pd.read_csv(f\"{DATA_PATH}/data/stock_returns.csv\")\n",
    "stocks.head(10) # Display the first few lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2fc210-9b82-4712-baa4-f1411dc7d33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the unique stocks we have in our dataframe\n",
    "stocks[\"Stock\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1d73be-8368-43d3-b954-73a021be919f",
   "metadata": {},
   "source": [
    "Say, you have this dataset of stock returns; however, you have another dataset where there is only the ticker for each company (the acronym in the parentheses, e.g., NOK, AAPL, etc.). How can we add a column `ticker` which contains only the ticker of each observation such that we would be able to merge both dataframes together?\n",
    "\n",
    "First, let's define a function that extracts the ticker for a single string. The company name always follows the pattern **company name (ticker)**. Remember what you learned about string manipulation in the previous notebook...\n",
    "\n",
    "The `.split()` method on a string lets us split a string into the characters before and after a delimiter, e.g.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6528406c-ea22-4bfc-9e4a-0e85cb16c9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the first company name at the whitespace ' '\n",
    "stocks.loc[0, \"Stock\"].split(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ded56e8-800e-4192-ae15-9461059c1151",
   "metadata": {},
   "source": [
    "Hence, what we can do to recover the ticker, is to simply apply this split, grab the last item of the list, i.e., the ticker in parentheses, and, strip it from any parentheses. Let's write a function for this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf9aaed-3b11-4649-b6cf-9f7be00de50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to recover the ticker from the full company name\n",
    "def recover_ticker(company_name):\n",
    "    # Split the name at the white spaces\n",
    "    name_split = company_name.split(\" \")\n",
    "    # Grab the last element of this split\n",
    "    ticker = name_split[-1]\n",
    "    # Strip it from parenteheses and return\n",
    "    return ticker.strip(\"()\")\n",
    "\n",
    "# 🤓 Oh and if you want to get fancy, this is the way you'd do it\n",
    "# you can verify yourself that it also works, much nicer don't you think?\n",
    "recover_ticker2 = lambda x: x.split(\" \")[-1].strip(\"()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd05147d-2b67-4cb3-989c-4e22e2e4f63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... does it work?\n",
    "[recover_ticker(company) for company in stocks[\"Stock\"].unique()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96878f9f-292f-46e9-ad4e-a59ae7255595",
   "metadata": {},
   "source": [
    "Neat! We can now use it on our dataframe. Intuitively, we can just loop over the dataframe and apply this function to each company right? Well we could, but we'll show this is not efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3b73f9-274b-400e-b909-de074ca27e44",
   "metadata": {},
   "source": [
    "#### ⛔ The *wrong* way\n",
    "Let's by doing it the *wrong* way, i.e., with a loop. I won't go into too many details of how to loop over the observations properly **because you should never do it! If you are looping over the observations in your dataframe, there is a very high chance you are doing something wrong and you should use vectorization instead!**\n",
    "\n",
    "Now, to clarify. There's generally nothing wrong with loops in computer science. But **loops in Python are not very efficient**. In fact, *vectorization* is doing nothing else than a loop, the reason it's so much faster is that the underlying package (`pandas` or `numpy`) makes use of parallelization as well as faster programming languages (e.g., C or C++) to do the computations in the background.\n",
    "\n",
    "So to summarize, the main concept is the following: Loops written in pure Python are slow. Using vectorization we are also writing loops but this can seem confusing, because we are writing them in a *different manner*. Now, instead of being interpreted in pure Python, when using vectorization, the package makes use of tricks to massively increase the speed of our loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ed10f8-6108-4c02-be04-b17578bb9104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by creating a column with the ticker, but put an empty string in there for now\n",
    "stocks[\"Ticker\"] = \"\"\n",
    "stocks # Display the data, our new column is there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4111a7-6a9e-4c13-a49e-29041cf1c6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# This %%time outputs the time needed for the cell to run\n",
    "\n",
    "# Iterate over every observation\n",
    "for i in stocks.index: \n",
    "    stocks.at[i, \"Ticker\"] = recover_ticker(stocks.loc[i, \"Stock\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9eceb02-c7fa-45b2-bfbf-76b6aae2c31f",
   "metadata": {},
   "source": [
    "Okay, roughly **170 milliseconds** (on my machine) for ~15'000 observations. Come on, it's not that bad is it? Well let's see what vectorization has to say about it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c725f51-37fe-45cf-93c8-e623130d43d6",
   "metadata": {},
   "source": [
    "#### ✅ The *right* way\n",
    "So, how does vectorization works anyway? Loops are simple enough right, but is vectorization also easy? Kind of.\n",
    "\n",
    "Remember how we can use methods on `pandas` dataframes, e.g., `.mean()` for the mean or `.std()` for the standard deviation? Well, we can use `.apply` and pass a function as an argument, this applies the function to the entire data column, so not only is it much faster computation-wise, it's actually also cleaner than first initializing empty columns and writing some cumbersome loops to fill them. Have a look!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7856f567-bdcb-432d-95bc-e5fdea65b432",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# A one-liner instead of what we did above...\n",
    "stocks[\"Ticker2\"] = stocks[\"Stock\"].apply(recover_ticker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a46d968-fd21-40bf-bbc3-361ace0f9ba0",
   "metadata": {},
   "source": [
    "___\n",
    "Roughly **15 ms** on the same machine, that's **a 95% speed increase compared to the pure Python loop! 🤯**\n",
    "___\n",
    "\n",
    "And, to be honest, this example is kind on loops, in fact, the loop runs in 170 milliseconds, we could deal with that. However, beginner data scientists often let their loops run for multiple hours, whereas a simple vectorization could have done the job in less than a few minutes. **I'm not exaggerating, I have seen this more than I can think of, and I've also done it myself when I didn't know better.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a210c43-c94f-4e69-80d5-037e43bdff6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks # Display the final data to make sure everything matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0982daa-1e2f-4f03-a42c-b317197f5d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you really want to make sure\n",
    "all(stocks[\"Ticker\"] == stocks[\"Ticker2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060394f9-4bb5-4d1a-9dcf-4d5d225add72",
   "metadata": {},
   "source": [
    "#### ➡️ ✏️ Task 1\n",
    "\n",
    "Time to try your own hand at vectorization. Say that you want to create a column `returns_binned`, where you group the return percentages into the following bins:\n",
    "\n",
    "+ $(-\\infty; -5] \\implies$ `\"extreme negative returns\"`\n",
    "+ $(-5;  -2] \\implies$ `\"large negative returns\"`\n",
    "+ $(-2; 0] \\implies$ `\"negative returns\"`\n",
    "+ $(0; +2] \\implies$ `\"positive returns\"`\n",
    "+ $(+2; +5] \\implies$ `\"large positive returns\"`\n",
    "+ $(+5; +\\infty) \\implies$ `\"extreme positive returns\"`\n",
    "\n",
    "Start by creating a function, `bin_returns`, which takes a single input and returns a **string** depending on the value of the input. Here is an input/output table, compare your outputs to it to make sure your function is right:\n",
    "\n",
    "|`input`|`output`|\n",
    "|---:|--:|\n",
    "|`1.5`|`\"positive returns\"`|\n",
    "|`3.6`|`\"large positive returns\"`|\n",
    "|`-6.52`|`\"extreme negative returns\"`|\n",
    "|`-0.7`|`\"negative returns\"`|\n",
    "|`8.34`|`extreme positive returns`|\n",
    "\n",
    "Once you are convinced that your function works, go ahead and add a column to the dataframe `stocks`. Do it with vectorization, but also with a loop, and compare the time difference using the `%%time` magic at the beginning of the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16252af9-3136-4ede-9205-a973e50f594a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here ➡️ ✏️\n",
    "def bin_returns(x):\n",
    "    \n",
    "    return "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
